{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1e18e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47662c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arnas\\AppData\\Local\\Temp\\ipykernel_30136\\3566616553.py:18: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df_base['Date'] = pd.to_datetime(df_base['Date'], dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating the final dataset creation process...\n",
      "Base dataset loaded and sorted by date.\n",
      "Generating Temporal League Rank for each match...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Ranks: 100%|██████████| 9232/9232 [00:00<00:00, 21617.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal League Rank columns added.\n",
      "Generating Temporal Team Strength for each match...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Strengths: 100%|██████████| 9232/9232 [00:00<00:00, 27465.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Team Strength columns added.\n",
      "\n",
      "✅ Success! The final dataset has been saved as 'full_feature_dataset_expanded.csv'.\n",
      "You can now run your training scripts again.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    try:\n",
    "        df = pd.read_csv(\"merged_dataset.csv\", encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        df = pd.read_csv(\"merged_dataset.csv\", encoding='ISO-8859-1')\n",
    "\n",
    "    print(\"Initiating the final dataset creation process...\")\n",
    "    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True, errors='coerce')\n",
    "    df.dropna(subset=['Date', 'HomeTeam', 'AwayTeam', 'FTR'], inplace=True)\n",
    "    df.sort_values(by='Date', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Base dataset loaded and sorted by date.\")\n",
    "    \n",
    "    # --- Betting Odds ---\n",
    "    home_odds_cols = [col for col in ['B365H', 'WHH', 'LBH'] if col in df.columns]\n",
    "    draw_odds_cols = [col for col in ['B365D', 'WHD', 'LBD'] if col in df.columns]\n",
    "    away_odds_cols = [col for col in ['B365A', 'WHA', 'LBA'] if col in df.columns]\n",
    "    df['Avg_Odds_H'] = df[home_odds_cols].mean(axis=1)\n",
    "    df['Avg_Odds_D'] = df[draw_odds_cols].mean(axis=1)\n",
    "    df['Avg_Odds_A'] = df[away_odds_cols].mean(axis=1)\n",
    "    # Simple forward-fill for any remaining missing odds\n",
    "    df[['Avg_Odds_H', 'Avg_Odds_D', 'Avg_Odds_A']] = df[['Avg_Odds_H', 'Avg_Odds_D', 'Avg_Odds_A']].fillna(method='ffill')\n",
    "\n",
    "    # --- Team Form ---\n",
    "    stats_cols = ['FTHG', 'FTAG', 'HTHG', 'HTAG' ,'HS', 'AS', 'HF', 'AF', 'HC', 'AC', 'HST', 'AST', 'HY', 'AY', 'HR', 'AR']\n",
    "    form_feature_names = [f'H_form_{col}' for col in stats_cols] + [f'A_form_{col}' for col in stats_cols]\n",
    "    \n",
    "    # This is a more efficient way to calculate rolling averages for form\n",
    "    for col in stats_cols:\n",
    "        df[f'H_form_{col}'] = df.groupby('HomeTeam')[col].transform(lambda x: x.shift(1).rolling(5, min_periods=1).mean())\n",
    "        df[f'A_form_{col}'] = df.groupby('AwayTeam')[col].transform(lambda x: x.shift(1).rolling(5, min_periods=1).mean())\n",
    "    df.dropna(subset=form_feature_names, inplace=True) # Drop early matches with no form data\n",
    "\n",
    "    # --- Head-to-Head (H2H) ---\n",
    "    # This part requires a loop, as it's context-dependent for each match\n",
    "    h2h_features = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating H2H\"):\n",
    "        home_team, away_team, date = row['HomeTeam'], row['AwayTeam'], row['Date']\n",
    "        h2h_df = df[((df['HomeTeam'] == home_team) & (df['AwayTeam'] == away_team)) | ((df['HomeTeam'] == away_team) & (df['AwayTeam'] == home_team))]\n",
    "        past_h2h = h2h_df[h2h_df['Date'] < date]\n",
    "        if len(past_h2h) == 0:\n",
    "            h2h_features.append([0, 0, 0])\n",
    "            continue\n",
    "        hw = len(past_h2h[(past_h2h['HomeTeam'] == home_team) & (past_h2h['FTR'] == 'H')])\n",
    "        aw = len(past_h2h[(past_h2h['AwayTeam'] == home_team) & (past_h2h['FTR'] == 'A')])\n",
    "        home_wins = hw + aw\n",
    "        draws = len(past_h2h[past_h2h['FTR'] == 'D'])\n",
    "        total_games = len(past_h2h)\n",
    "        h2h_features.append([(home_wins / total_games), ((total_games - home_wins - draws) / total_games), (draws / total_games)])\n",
    "    \n",
    "    h2h_df = pd.DataFrame(h2h_features, columns=['H_H2H_win_pct', 'A_H2H_win_pct', 'H2H_draw_pct'], index=df.index)\n",
    "    df = pd.concat([df, h2h_df], axis=1)\n",
    "\n",
    "    # --- 4. Feature Engineering: Advanced Temporal Features ---\n",
    "    print(\"Generating Temporal League Rank for each match...\")\n",
    "    \n",
    "    # --- Temporal League Rank ---\n",
    "    def get_season(date):\n",
    "        return f\"{date.year}-{date.year + 1}\" if date.month >= 8 else f\"{date.year - 1}-{date.year}\"\n",
    "    df['Season'] = df['Date'].apply(get_season)\n",
    "    ranks_home, ranks_away = [], []\n",
    "    points_cache = defaultdict(lambda: defaultdict(int))\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating Ranks\"):\n",
    "        season, home, away = row['Season'], row['HomeTeam'], row['AwayTeam']\n",
    "        season_points = points_cache[season]\n",
    "        standings = sorted(season_points.items(), key=lambda item: item[1], reverse=True)\n",
    "        rank_map = {team: r + 1 for r, (team, p) in enumerate(standings)}\n",
    "        ranks_home.append(rank_map.get(home, 15))\n",
    "        ranks_away.append(rank_map.get(away, 15))\n",
    "        if row['FTR'] == 'H': points_cache[season][home] += 3\n",
    "        elif row['FTR'] == 'A': points_cache[season][away] += 3\n",
    "        else: points_cache[season][home] += 1; points_cache[season][away] += 1\n",
    "    df['HomeTeam_League_Rank'] = ranks_home\n",
    "    df['AwayTeam_League_Rank'] = ranks_away\n",
    "    print(\"Temporal League Rank columns added.\\nGenerating Temporal Team Strength for each match...\")\n",
    "    # --- Temporal Team Strength (Elo) ---\n",
    "    strength_home, strength_away = [], []\n",
    "    strength_cache = defaultdict(lambda: 1500)\n",
    "    K = 30\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Calculating Strengths\"):\n",
    "        home, away = row['HomeTeam'], row['AwayTeam']\n",
    "        r_h, r_a = strength_cache[home], strength_cache[away]\n",
    "        strength_home.append(r_h); strength_away.append(r_a)\n",
    "        e_h = 1 / (1 + 10**((r_a - r_h) / 400))\n",
    "        e_a = 1 - e_h\n",
    "        if row['FTR'] == 'H': s_h, s_a = 1, 0\n",
    "        elif row['FTR'] == 'A': s_h, s_a = 0, 1\n",
    "        else: s_h, s_a = 0.5, 0.5\n",
    "        n_r_h = r_h + K * (s_h - e_h)\n",
    "        n_r_a = r_a + K * (s_a - e_a)\n",
    "        strength_cache[home], strength_cache[away] = n_r_h, n_r_a\n",
    "    df['HomeTeam_Strength'] = strength_home\n",
    "    df['AwayTeam_Strength'] = strength_away\n",
    "    print(\"Temporal Team Strength columns added.\")\n",
    "    # --- 5. Final Save ---\n",
    "    output_path = \"full_feature_dataset_expanded.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(\"✅ Success! The final dataset has been saved as 'full_feature_dataset_expanded.csv'.\\nYou can now run your training scripts again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dab82748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 1/3] Loading data and creating a unified train/test split...\n",
      "Data split successfully.\n",
      "\n",
      "[STEP 2/3] Training and evaluating the Pure CatBoost model on the test set...\n",
      "0:\tlearn: 1.0755762\ttest: 1.0757772\tbest: 1.0757772 (0)\ttotal: 189ms\tremaining: 3m 8s\n",
      "100:\tlearn: 0.7523771\ttest: 0.7996716\tbest: 0.7995851 (99)\ttotal: 4.52s\tremaining: 40.2s\n",
      "200:\tlearn: 0.6893679\ttest: 0.7899262\tbest: 0.7898549 (191)\ttotal: 8.58s\tremaining: 34.1s\n",
      "300:\tlearn: 0.6234841\ttest: 0.7887683\tbest: 0.7880250 (273)\ttotal: 12.6s\tremaining: 29.2s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.7880250326\n",
      "bestIteration = 273\n",
      "\n",
      "Shrink model to first 274 iterations.\n",
      "\n",
      "[STEP 3/3] Assembling and saving the final asset toolkit for this model...\n",
      "\n",
      "✅ Success! The Pure CatBoost model toolkit has been saved to 'pure_catboost_assets.pkl'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arnas\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Load and Split Data ---\n",
    "print(\"\\n[STEP 1/3] Loading data and creating a unified train/test split...\")\n",
    "current_dir = os.getcwd()\n",
    "df_final = pd.read_csv(os.path.join(current_dir, \"full_feature_dataset_expanded.csv\"))\n",
    "df_final = df_final.dropna()\n",
    "\n",
    "feature_list = [\n",
    "    'HomeTeam', 'AwayTeam', 'Season', 'HTHG', 'HTAG', 'HS', 'AS', 'AST', 'HST', \n",
    "    'HC', 'AC', 'HY', 'AY', 'HR', 'AR', 'HF', 'AF', \n",
    "    'HomeTeam_League_Rank', 'AwayTeam_League_Rank', 'HomeTeam_Strength', 'AwayTeam_Strength'\n",
    "] + [col for col in df_final.columns if 'Avg_Odds' in col or 'form' in col or 'H2H' in col]\n",
    "\n",
    "X = df_final[feature_list].copy()\n",
    "y = df_final['FTR']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Data split successfully.\")\n",
    "\n",
    "\n",
    "# --- Step 2: Train and Evaluate the Pure CatBoost Model ---\n",
    "print(\"\\n[STEP 2/3] Training and evaluating the Pure CatBoost model on the test set...\")\n",
    "cat_features = ['HomeTeam', 'AwayTeam', 'Season']\n",
    "le_target = LabelEncoder()\n",
    "y_train_encoded = le_target.fit_transform(y_train)\n",
    "y_test_encoded = le_target.transform(y_test)\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=7,\n",
    "    loss_function='MultiClass',\n",
    "    auto_class_weights='Balanced',\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=100\n",
    ")\n",
    "model.fit(X_train, y_train_encoded, cat_features=cat_features, eval_set=(X_test, y_test_encoded))\n",
    "\n",
    "y_pred_encoded = model.predict(X_test)\n",
    "y_pred = le_target.inverse_transform(y_pred_encoded)\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 3: Save the Final Assets (Optional, if you choose this model) ---\n",
    "print(\"\\n[STEP 3/3] Assembling and saving the final asset toolkit for this model...\")\n",
    "final_assets = {\n",
    "    'model': model,\n",
    "    'target_encoder': le_target,\n",
    "}\n",
    "file_path = 'pure_catboost_assets.pkl'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(final_assets, file)\n",
    "\n",
    "print(f\"\\n✅ Success! The Pure CatBoost model toolkit has been saved to '{file_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab8fd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------\n",
      "Pure CatBoost System Accuracy: 64.59%\n",
      "-------------------------------------------------\n",
      "\n",
      "Pure CatBoost System Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.72      0.69      0.70       549\n",
      "           D       0.39      0.49      0.43       453\n",
      "           H       0.79      0.70      0.75       845\n",
      "\n",
      "    accuracy                           0.65      1847\n",
      "   macro avg       0.63      0.63      0.63      1847\n",
      "weighted avg       0.67      0.65      0.66      1847\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\n-------------------------------------------------\")\n",
    "print(f\"Pure CatBoost System Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"-------------------------------------------------\")\n",
    "print(\"\\nPure CatBoost System Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
